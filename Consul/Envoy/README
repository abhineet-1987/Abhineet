kubectl debug -it static-server-74bd9c5d5b-hghkc --target=consul-dataplane --image=nicolaka/netshoot -- sh

~ # curl localhost:19000/listeners
outbound_listener:127.0.0.1:15001::127.0.0.1:15001
public_listener:10.244.0.15:20000::10.244.0.15:20000

#########
outbound_listener:127.0.0.1:15001::127.0.0.1:15001
This is Envoy‚Äôs outbound listener.
Purpose: intercepts all egress traffic from your application container (the sidecar model).
Port 15001 is the standard ‚Äúcapture port‚Äù used by Envoy in service mesh setups (similar to Istio).
Traffic flow:
Your app sends traffic to some external service.
iptables redirects it into Envoy‚Äôs port 15001.
Envoy applies Consul Connect policies (mTLS, intentions, routing).
Envoy then forwards it to the correct upstream destination.
Bound to 127.0.0.1 because it‚Äôs local to the dataplane container.

###########
public_listener:10.244.0.15:20000::10.244.0.15:20000
This is Envoy‚Äôs inbound listener (sometimes called ‚Äúpublic listener‚Äù).
Purpose: accepts incoming traffic destined for your service.
Port 20000 is the default ‚Äúservice port‚Äù Envoy uses to expose the proxied application.
Traffic flow:
Other services in the mesh connect to this IP:20000.
Envoy terminates mTLS (using the Connect CA).
Envoy forwards the decrypted traffic to your application‚Äôs real port (inside the pod).
Bound to the pod‚Äôs IP (10.244.0.15 in your case), so other pods in the cluster can reach it.

Summary
Outbound listener (15001) ‚Üí Captures and secures traffic leaving your app.
Public listener (20000) ‚Üí Accepts and secures traffic coming into your app.
Together, they implement Consul Connect‚Äôs sidecar proxy model:
Outbound listener ensures all egress traffic is subject to mTLS + intentions.
Public listener ensures all ingress traffic is authenticated and encrypted.

üëâ In short:
15001 (outbound) = Envoy intercepts your app‚Äôs outgoing traffic.
20000 (public/inbound) = Envoy receives incoming traffic for your app, applies mTLS, and forwards it internally.

---------------------------------------------------------------------

localhost:19000/clusters
<cluster_name>::<scope>::<metric>::<value>
cluster_name = logical upstream (e.g., local_app, consul-dataplane, original-destination)
scope = priority level, endpoint address, or metadata
metric = what‚Äôs being measured (connections, requests, retries, etc.)
value = current counter or setting

local_app cluster
This represents your application itself (the service Envoy is proxying).

consul-dataplane cluster
This represents Envoy‚Äôs connection back to the Consul dataplane control server (for xDS config, mTLS cert rotation, etc.).

original-destination cluster
This is a special Envoy cluster used for transparent proxying.

~ # curl localhost:19000/clusters
original-destination::observability_name::original-destination
original-destination::default_priority::max_connections::1024
original-destination::default_priority::max_pending_requests::1024
original-destination::default_priority::max_requests::1024
original-destination::default_priority::max_retries::3
original-destination::high_priority::max_connections::1024
original-destination::high_priority::max_pending_requests::1024
original-destination::high_priority::max_requests::1024
original-destination::high_priority::max_retries::3
original-destination::added_via_api::true
consul-dataplane::observability_name::consul-dataplane
consul-dataplane::default_priority::max_connections::1024
consul-dataplane::default_priority::max_pending_requests::1024
consul-dataplane::default_priority::max_requests::1024
consul-dataplane::default_priority::max_retries::3
consul-dataplane::high_priority::max_connections::1024
consul-dataplane::high_priority::max_pending_requests::1024
consul-dataplane::high_priority::max_requests::1024
consul-dataplane::high_priority::max_retries::3
consul-dataplane::added_via_api::false
consul-dataplane::127.0.0.1:34171::cx_active::1
consul-dataplane::127.0.0.1:34171::cx_connect_fail::0
consul-dataplane::127.0.0.1:34171::cx_total::1
consul-dataplane::127.0.0.1:34171::rq_active::0
consul-dataplane::127.0.0.1:34171::rq_error::1883
consul-dataplane::127.0.0.1:34171::rq_success::0
consul-dataplane::127.0.0.1:34171::rq_timeout::0
consul-dataplane::127.0.0.1:34171::rq_total::1883
consul-dataplane::127.0.0.1:34171::hostname::
consul-dataplane::127.0.0.1:34171::health_flags::healthy
consul-dataplane::127.0.0.1:34171::weight::1
consul-dataplane::127.0.0.1:34171::region::
consul-dataplane::127.0.0.1:34171::zone::
consul-dataplane::127.0.0.1:34171::sub_zone::
consul-dataplane::127.0.0.1:34171::canary::false
consul-dataplane::127.0.0.1:34171::priority::0
consul-dataplane::127.0.0.1:34171::success_rate::-1
consul-dataplane::127.0.0.1:34171::local_origin_success_rate::-1
local_app::observability_name::local_app
local_app::default_priority::max_connections::1024
local_app::default_priority::max_pending_requests::1024
local_app::default_priority::max_requests::1024
local_app::default_priority::max_retries::3
local_app::high_priority::max_connections::1024
local_app::high_priority::max_pending_requests::1024
local_app::high_priority::max_requests::1024
local_app::high_priority::max_retries::3
local_app::added_via_api::true
local_app::127.0.0.1:8080::cx_active::0
local_app::127.0.0.1:8080::cx_connect_fail::0
local_app::127.0.0.1:8080::cx_total::3504
local_app::127.0.0.1:8080::rq_active::0
local_app::127.0.0.1:8080::rq_error::0
local_app::127.0.0.1:8080::rq_success::0
local_app::127.0.0.1:8080::rq_timeout::0
local_app::127.0.0.1:8080::rq_total::14
local_app::127.0.0.1:8080::hostname::
local_app::127.0.0.1:8080::health_flags::healthy
local_app::127.0.0.1:8080::weight::1
local_app::127.0.0.1:8080::region::
local_app::127.0.0.1:8080::zone::
local_app::127.0.0.1:8080::sub_zone::
local_app::127.0.0.1:8080::canary::false
local_app::127.0.0.1:8080::priority::0
local_app::127.0.0.1:8080::success_rate::-1
local_app::127.0.0.1:8080::local_origin_success_rate::-1

xDS config is Envoy‚Äôs dynamic configuration system that lets it fetch routing, cluster, listener, and security settings from an external control plane ‚Äî in Consul‚Äôs case, the Consul dataplane agent. 
It enables real-time updates without restarting Envoy.
Envoy starts up with a minimal bootstrap config.
It connects to the Consul dataplane agent via gRPC on a local ephemeral port (e.g., 127.0.0.1:34171).
The dataplane agent fetches service mesh config from Consul servers.
It streams xDS updates to Envoy:
Which services exist
  What listeners to bind
  What clusters to route to
  What TLS certs to use
  What ACLs (intentions) to enforce
This allows Envoy to dynamically adapt to changes in the mesh ‚Äî new services, updated routes, rotated certs ‚Äî without restarting.

The dataplane agent ‚Üî Envoy link is always gRPC, because xDS APIs are gRPC services.
The ephemeral port (like 34171) is the local gRPC endpoint where Envoy connects to fetch dynamic config.
Envoy connects to the Consul dataplane agent on a local ephemeral port (like 127.0.0.1:34171) using gRPC.
This channel is one‚Äëway in purpose: Envoy asks for xDS config, and the dataplane agent streams updates down to Envoy.

envoy -> consul dataplane (127.0.0.1:34171 local ephemeral port) -> consul server (grpc 8502) -> consul dataplane -> envoy

Consul servers do not send requests to a dataplane port.
Instead, the dataplane agent connects outbound to Consul servers on port 8502.
The servers then stream mesh config (clusters, listeners, certs) back over that gRPC connection.
Inside the pod, the dataplane agent passes that config to Envoy via its local ephemeral port (like 127.0.0.1:34171).

Consul servers always send config down to dataplane over port 8502 (dataplane initiates).
Dataplane passes config to Envoy over a local ephemeral port (like 34171).
Envoy handles all service traffic via 15001/20000, not the dataplane agent.

######### For static server and static client apps in k8 ############

# curl localhost:19000/clusters       # executed on static-client consul-dataplane container

You'll see the endpoints for static-server cluster as (If Intentions are defined):

static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::observability_name::static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::outlier::success_rate_average::-1
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::outlier::success_rate_ejection_threshold::-1
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::outlier::local_origin_success_rate_average::-1
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::outlier::local_origin_success_rate_ejection_threshold::-1
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::default_priority::max_connections::1024
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::default_priority::max_pending_requests::1024
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::default_priority::max_requests::1024
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::default_priority::max_retries::3
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::high_priority::max_connections::1024
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::high_priority::max_pending_requests::1024
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::high_priority::max_requests::1024
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::high_priority::max_retries::3
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::added_via_api::true
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::cx_active::0
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::cx_connect_fail::0
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::cx_total::0
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::rq_active::0
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::rq_error::0
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::rq_success::0
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::rq_timeout::0
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::rq_total::0
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::hostname::
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::health_flags::healthy
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::weight::1
static-server.default.dc1.internal.702e0bdb-3fcf-0fba-61f2-82e0549c3902.consul::10.244.0.14:20000::region::

If intentions are not created, then you won't see the above static-server cluster endpoints in the output of localhost:19000/clusters when executed on consul-dataplane container of static-client pod.




